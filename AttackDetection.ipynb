{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OsmanTurgut2335/covid-data-project/blob/main/AttackDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HshSv4ZuWBC2"
      },
      "outputs": [],
      "source": [
        "pip install pandas openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9NfUbH-WXrF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Excel dosyasından veri setini yükle\n",
        "df = pd.read_excel('db.xlsx')\n",
        "\n",
        "# Veri setinin ilk birkaç satırını görüntüle\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uflR6eMEGTaJ"
      },
      "outputs": [],
      "source": [
        "# Enerji (energy) hesaplama\n",
        "df['energy_mWh'] = df['current_mA'] * df['bus_voltage_V']\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7riSB3XXmF1"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding işlemi\n",
        "df_encoded = pd.get_dummies(df, columns=['State', 'Attack'])\n",
        "\n",
        "# Kodlanmış veri setinin ilk birkaç satırını görüntüle\n",
        "print(df_encoded.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC_1vbKvXl6q"
      },
      "outputs": [],
      "source": [
        "# Özellikleri (X) ve hedef değişkeni (y) ayır\n",
        "X = df_encoded[['shunt_voltage','bus_voltage_V', 'current_mA', 'power_mW','State_charging', 'State_idle']]\n",
        "y = df_encoded[['Attack_Backdoor', 'Attack_cryptojacking', 'Attack_none',\n",
        "    'Attack_syn-flood', 'Attack_syn-stealth', 'Attack_tcp-flood', 'Attack_vuln-scan']]\n",
        "\n",
        "# Normalleştirme için min-max ölçekleyici veya standart ölçekleyici kullanılabilir\n",
        "# Ölçekleyiciyi başlat\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Özellikleri normalleştir\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Veri kümesini eğitim ve test setlerine ayır\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_normalized, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuN91VbPdWqf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer='adam',   #optimizasyon algoritması\n",
        "              loss='categorical_crossentropy',  #kayıp fonksiyonu\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Modeli eğit\n",
        "history =model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.3)  # Gerektiğinde epoch ve toplu boyut sayısını ayarlayabilirsiniz\n",
        "\n",
        "# Test seti üzerinde modeli değerlendir\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "# Get the weights of the trained model\n",
        "layer_weights = model.get_weights()\n",
        "\n",
        "# Extract the weights of the first layer (input layer to the first hidden layer)\n",
        "input_layer_weights = layer_weights[0]\n",
        "\n",
        "# Calculate the absolute sum of weights for each feature\n",
        "feature_importance = np.sum(np.abs(input_layer_weights), axis=1)\n",
        "\n",
        "# Normalize feature importance scores\n",
        "feature_importance /= np.sum(feature_importance)\n",
        "\n",
        "# Match feature importance scores with feature names\n",
        "feature_names = X.columns\n",
        "\n",
        "# Create a dictionary to store feature importance scores with feature names\n",
        "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
        "\n",
        "\n",
        "# Sort feature importance scores in descending order\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract feature names and importance scores\n",
        "features, importance = zip(*sorted_feature_importance)\n",
        "\n",
        "# Plotting feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(range(len(features)), importance, align='center')\n",
        "plt.yticks(range(len(features)), features)\n",
        "plt.xlabel('Normalized Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r1hcMZI2M4CD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuvdQkn2dX5J"
      },
      "outputs": [],
      "source": [
        "# Eğitim ve doğrulama kaybını çiz\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Kayıp')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Excel dosyasından veri setini yükle\n",
        "external_data_df = pd.read_excel('simulation_logs.xlsx')\n",
        "\n",
        "# Veri setinin ilk birkaç satırını görüntüle\n",
        "print(external_data_df.head())\n",
        "\n",
        "# One-hot encoding işlemi için 'State' sütununu ekleyin\n",
        "external_data_encoded = pd.get_dummies(external_data_df, columns=['State'])\n",
        "\n",
        "# One-hot encoding yapıldıktan sonra veri kümesini görüntüleyin\n",
        "print(external_data_encoded.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s9TupvOpgdwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding yapılan veri kümesinden gerekli özellikleri seçin\n",
        "X_external_encoded = external_data_encoded[['shunt_voltage', 'bus_voltage_V', 'current_mA', 'power_mW', 'State_charging', 'State_idle']]\n",
        "\n",
        "# Verileri ölçekleyin\n",
        "X_external_normalized = scaler.transform(X_external_encoded)\n",
        "\n",
        "# Modeli kullanarak tahmin yapın\n",
        "predictions = model.predict(X_external_normalized)\n",
        "\n",
        "# Tahmin olasılıklarını yazdırın (her bir sınıf için olasılık)\n",
        "print(predictions)\n",
        "\n",
        "# En yüksek olasılığa sahip olan sınıfı seçin\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Tahmin edilen sınıfları yazdırın\n",
        "print(predicted_classes)\n",
        "\n",
        "class_names = ['Attack_Backdoor', 'Attack_cryptojacking', 'Attack_none', 'Attack_syn-flood', 'Attack_syn-stealth', 'Attack_tcp-flood', 'Attack_vuln-scan']\n",
        "\n",
        "predicted_class_names = [class_names[idx] for idx in predicted_classes]\n",
        "\n",
        "print(predicted_class_names)\n"
      ],
      "metadata": {
        "id": "K7aT5dvYhH6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin edilen sınıfları sütun olarak ekleyin\n",
        "external_data_df['Predicted_Attack'] = predicted_class_names\n",
        "\n",
        "# Veri setinin güncellenmiş halini gözden geçirin\n",
        "print(external_data_df.head())\n",
        "\n",
        "# Güncellenmiş veri setini Excel dosyasına kaydedin\n",
        "external_data_df.to_excel('tahmin_edilen.xlsx', index=False)\n",
        "\n",
        "print(\"Tahmin edilen sınıflar Excel dosyasına başarıyla eklendi.\")\n"
      ],
      "metadata": {
        "id": "LRxD3IhFiebu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgxgkephdcBU",
        "outputId": "51bbbf7b-8878-48e3-94f7-d7f7da67c99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.6282201405152225\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Random Forest modelini oluşturun\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Modeli eğitin\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Modelin performansını değerlendirin\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "\n",
        "\n",
        "def preprocessing(filename):\n",
        "  \"\"\"\n",
        "  Excel dosyasını okur, temizler ve istatistiğini döndürür\n",
        "  :param filename: .xlsx formatındaki dosya path'i\n",
        "  \"\"\"\n",
        "  df = pd.read_excel(filename)\n",
        "  df.dropna(inplace=True)\n",
        "  print(\"Columns:\\n\", df.columns)\n",
        "  print(\"\\nInfo:\\n\", df.info())\n",
        "  print(\"\\nDescription:\\n\", df.describe())\n",
        "  print(\"\\nUnique values of the column 'Attack':\\n\", df['Attack'].unique())\n",
        "  print(\"\\nUnique values of the column 'State':\\n\", df['State'].unique())\n",
        "  return df\n",
        "\n",
        "\n",
        "def training(df):\n",
        "  \"\"\"\n",
        "  Modelin Representation aşamasıdır, encoding, scaling ve training yapılır\n",
        "  :param df: Temizlenmiş DataFrame\n",
        "  \"\"\"\n",
        "  # Encoding ve değişken ayırma işlemi\n",
        "  encoded_df = pd.get_dummies(df, columns=['State']) # Bağımsız değişkenlere\n",
        "  X = encoded_df.drop('Attack', axis=1)\n",
        "  y = encoded_df['Attack']\n",
        "\n",
        "  # Scaling işlemi, StandardScaler burada uygun olmayabilir\n",
        "  scaler = MinMaxScaler(feature_range=(0, 10))\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "  # Train-Test kümeleri ayrışımı\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X_scaled, y, test_size=0.2, random_state=42\n",
        "  )\n",
        "\n",
        "  # Model eğitimi, çok sınıflı Lojistik Regresyon algoritması kullanılır\n",
        "  model = LogisticRegression(\n",
        "      multi_class='multinomial', solver='lbfgs', max_iter=1000\n",
        "  )\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  return model, X_test, y_test\n",
        "\n",
        "\n",
        "def evaluation(model, X_test, y_test):\n",
        "  \"\"\"\n",
        "  Eğitilen model ile tahminler yapılır ve sonuçlar incelenir\n",
        "  :param model: Eğitilmiş model\n",
        "  :param X_test: Test edilecek veri, bağımlı değişken yok\n",
        "  :param y_test: Hedef sütunun gerçek değerleri\n",
        "  \"\"\"\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"\\nAccuracy değeri:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "  print(\"\\nPrecision Score:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "  print(\"\\nRecall Score:\", recall_score(y_test, y_pred, average='weighted'), '\\n')\n",
        "\n",
        "\n",
        "def main():\n",
        "  filename = \"db.xlsx\"\n",
        "  data = preprocessing(filename)\n",
        "  trained_model, X_test, y_test = training(data)\n",
        "  evaluation(trained_model, X_test, y_test)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "metadata": {
        "id": "_z61pZby3Ev9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KDwpTxTVVYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}